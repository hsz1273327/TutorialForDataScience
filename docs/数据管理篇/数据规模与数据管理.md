# 数据规模和数据管理

随着数据规模的增加,数据管理手段和工具都需要做出响应变化,之所以不同规模的数据要用不通的技术手段,根本上来说是机器的资源无法满足大规模存储/计算的需求.再往深了说是高资源配置的机器太贵了.因此可以看到几乎所有的大数据解决方案都是集群化方案--利用大量便宜的低配置机器组成集群,通过调度管理程序统一调配资源:

1. 将任务拆分重构为子任务构成的任务图放入调度器
2. 借助队列将任务分发到多台机器处理然后再聚合

数据管理当然也需要根据不同的数据规模来调整数据管理方式和使用的工具.

## 数据的存储环境

无论是什么规模的企业业务,必定会需要3种数据:

1. 业务数据,简单说就是业务上要直接使用的数据
2. 分析数据,简单说就是业务上不直接使用,而是帮助业务改进,企业决策的数据.
3. 开发数据,简单说就是开发业务需要的文档,代码,客户资料,供应链资料等信息.

这两种数据使用场景不同,因此管理的方式也不同

## 不同规模下的技术选型

基本上技术选型需要考虑的是资源成本和预期收益,说到底数据是为盈利服务的.

比如一个赔钱的业务,那它就没有必要做什么数据管理,因为投的多赔的多;

如果是小本经营比如小区里开个小面包店,那它就比较适合将业务和数据结合管理,买台2000块的电脑,装个office,每天一张excel表就足以解决问题;

如果面包店开大了,连锁了有了两家分店,那不同分店间的数据对账就成了问题,这时候就需要一个所谓的数据中心(总店里电脑升级下配置,加块ssd,和运营商开下对外端口)来维护每个店的资源和资金;

面包店希望做到更好的提高回头客的比例,希望通过会员制等措施知道客户希望买到什么样的面包,这个时候就需要有算法,有分析的进入,就会有推荐,用户调研,决策支持等需求,这个时候就需要再升级数据中心的配置,更大的内存更多强的cpu,甚至多机组成集群,需要有定时任务分析每天的交易情况;

随着面包店的扩大数据越来越多,数据存在哪里成了问题,一来全存存不下,要想存下需要花很多钱买硬盘,二来数据多了搜索,调用性能堪忧,这时候数据就需要按热度分出生命周期,处在生命周期不同阶段的数据放在不同的工具中,用的多的数据放在高性能高价的存储介质中,用的少的只是留档就放在最便宜的设备中.数据的分析也分析不过来--用于分析的数据规模大于单机的内存,这个时候就要借助分布式计算框架,比如spark,比如dask.

再进一步的面包店希望数据的分析结果可以实时的反馈给门店,快速响应跟上市场的变化,这个时候就需要引入流的概念,使用流处理工具.

上面的例子可以看出技术只是手段,是为了解决问题才发展出来的,因此什么阶段使用什么样的技术,不同阶段间技术如何过度就成了技术选型需要考虑的问题.

本文给出的技术选型方案是渐进式的,没有替换只有增加和撤销,这点需要注意,另外在可以满足需求的情况下不要没事尝试新的技术或者使用下一阶段的技术,尝试新技术是个试错的过程,必然会有大量失败浪费大量人力物力,尤其是在公司还规模小的时候.不少公司是折腾死的.

另外一个需要注意的是关于部署的问题,原则上我个人不支持直接部署,更加支持使用docker部署一切需要部署的业务程序.利用容器配合k8s或者swarm技术可以大大降低运维成本.而一些基础组件比如数据库,缓存,消息中间件等为了更加可靠更加建议如果不是自建机房就购买运营商的专业服务,这样可以省很多运维成本.如果是自建机房则建议单独购买机器专门配置运维.


### 起步阶段

> 业务数据

而如果业务上需要快速查找快速响应,甚至需要有服务器,那么比较推荐的是云端架设,同时直接购买其上的数据库服务,最好是postgresql,以方便如果有后续的话可以直接迁移,并且最好选择按量付费的版本.原因在于没有持有成本,在快速试错后如果起步阶段就失败了,那么不需要继续支持这部分成本.虽然从长期看这种业务部署方案很不划算,但考虑到失败的概率比成功高太多,这反而是比较实惠的方案.

> 分析数据

在业务初期,盲目的追求新技术往往得不偿失,业务初期的首要目标永远是赚钱,先能活下去再考虑如何提高效率.如果提高了效率也不能赚钱那就更加得不偿失了,因为业务小,所以数据量也小,一天的数据量可能也就一个100M以下的excel文件就可以保存.因此快速试错快速失败才是业务初期对数据的最大需求.正如上面的例子所说,分析部分的数据excel(office,wps)就是初期最好的管理工具:

1. 廉价
    本身几乎免费,人力方面--几乎人人都会用excel而且学习成本极低.这项技能甚至都不用写到招聘需求里
2. 功能够用
    即便不会vb编程,不会写宏,excel也已经可以用作记录,筛选,查找,分类,可视化的功能,足以满足绝大多数数据方面的需求.
3. 存储灵活
    excel说白了是文件存储,这就意味着可以很灵活的存储,可以放硬盘,移动硬盘,u盘都行
4. 足以应付简单分析需要

如果业务数据在云端,那么每天定时同步下来保存一份当天的数据,导成excel文件,然后放在同一个移动硬盘里,需要的时候取出来拿excel分析即可.

> 开发数据

而开发数据,个人认为需要按机密性划分存储位置,比如如果是代码,那么比较适合的是放在线上,因为
1. 放心,你写出来的代码没人看得上
2. 代码在线上可以直接用于测试,部署的自动化,在起步阶段人力紧张的的条件下可以大大的提高效率,提高试错频率.

个人推荐像代码,开发出来的服务使用文档,开发进度计划,这类东西都可以直接在github上托管,一来不需要自己部署省心,二来功能完全够用,现代的运维自动化工具,敏捷开发管理工具全部都支持github,毕竟是全世界最大的开源开发者社区,三来个人用户完全免费,还有github page这种工具可以自己免费搭建静态网站.

但是如果是比如客户资料,供应链资料,资金数据这些则一定要本地存储.并且要加密,这些一样可以使用excel,excel有加密功能,一般情况下还是比较安全的.

#### 总结

起步阶段使用业务数据使用`云服务器+postgresql`,分析数据使用`excel`保存和计算,开发数据使用`github+本地文档+u盘移动硬盘`

### 初期阶段

此处业务初期指业务已经找到了盈利模式,可以稳定增长,可以养得起技术团队并且有继续做大想法的阶段.这个阶段的特点是业务已经成型,但规模没有上去.这个阶段的主要任务就是修好内功打好地基,为后续扩大规模抢占市场提供支持.

这个阶段往往是项目成败的关键,往往一个企业的骨架就是在这个时候定型的,通常这个阶段只会存在最长1年时间,但这一年之后的所有行为可能都是这一年中决定的延续.

这个阶段企业要定好利益分配框架,权力分配架构,技术架构,当然了企业本身架构不是本文的讨论范围,而且远比技术架构的成型原因复杂的多.一个足够优秀技术架构可以让企业在快速扩张时在技术方面降低内耗,专心于业务.但技术架构往往也是由利益分配框架和权力分配架构影响形成的,比如创始人中有精通java的并且权力很大,那很容易就影响到技术栈会用全套java.没有人懂技术,那很可能就是谁出钱多就听谁瞎指挥.因此比较建议任何初创团队都应该有一个懂数据的创始人.

当然了能安然度过这个阶段其实已经是胜利了,毕竟很多企业活不过两年.

这个阶段的数据量会上来,一天的数据量可能可以上G,但基本不会超过100G,基本还是在单机可以处理的程度.但基本的数据相关架构就已经可以根据需求完善起来了.

这个阶段依然建议不要自建机房,而是使用阿里云腾讯云aws这样的服务商提供的虚拟主机和运维服务.自建机房不光是费钱的问题,更多的是需要耗费人力,运维工作非常专业化,专业人员贵,非专业人员又难以解决问题.就我了解有不少公司原本有自建机房的也都纷纷上了云.这个阶段并不适合自建机房.如果有自建机房的需求建议在稳定阶段逐步迁移.

业务部分我们放在云服务器上,分析数据这个阶段同样适合放在云上,各个运营商都有现成的分析数据存储和计算方案,比如对象存储几乎各家都有,可以作为廉价温数据存储方案,一般运营商也都会提供spark集群,用来计算温数据的统计信息.但这个阶段已经可以在本地搭建nas来做冷数据存储和辅助资料,文档等的存储了.

> 业务数据

初期业务数据存储方案一般还是使用数据库.选数据库时比较建议直接使用postgresql,而不是跟风用什么mysql或者其他nosql数据库.

1. 廉价
    postgresql本身开源,任何人都可以安装使用,pg使用sql语句作为通用的交互接口,任何学过数据库的人一定都会使用sql,因此人力成本上相对也不高.pg的运维成本也不高,只是国内用的人少会让人觉得难,实际上它的文档相当齐全,本身设计优秀几乎不需要额外的运维.至于学习成本其实更低了,官方文档有高质量的中文翻译,大多数问题都可以看它解决.

2. 功能全

    postgresql几乎是最全能的数据库.丰富的扩展让它可以满足几乎所有需求.目前除了列存储貌似没发现有它不支持的

3. 使用的生命周期长

    postgresql可以在进入整个业务技术栈后就一直有一席之地.开始可以全部使用它来存储数据,甚至可以做广播器.慢慢的业务扩大了可以分表,可以将一些特殊数据存入其扩展,比如时序数据库timescale,再然后可以作为热数据的存储工具.

当然这个阶段就需要有相关的技术人员参与了,建议招聘有编程能力的专业技术人员或者自己学习运维,而不是只会改配置的所谓运维.一个这样的人可以管整个数据层,在下一个阶段之前都可以不需要额外的人手,后续只是给他找帮手而已.

> 分析数据

当不再满足于存储和简单查询这样的方式来利用数据时,比如要分析用户时,就需要专业的数据分析人员了.这个阶段初期一样需要的技术还是postgresql和excel.但成本是在人力上,数据分析数据挖掘是技术活,并不是人人可以做,这个阶段一般技术栈有两种

1. sql进阶+excel进阶,sql语句本身图灵完备,pg完全支持复杂的sql查询语句,那问题就在人会不会写复杂的查询语句了.查出需要的数据后可以导入excel借助插件做方差分析等数据分析工作,并且可以使用excel自带的工具做数据可视化.这个技术栈好处是没有引入任何新的技术,只是在老技术上做深化.事实上很多传统行业都是这么做的.但瓶颈实际上在excel上,excel可以处理的数据量有限,文件一旦过大无论打开还是计算都会很低效;同时支持的算法少,自己写算法也麻烦.当然如果这个方案足够使用那就没必要引入新的技术栈了.

2. sql进阶+python数据科学工具组,所谓的python数据科学工具组大致就是numpy+scipy+pandas+sklearn+StatsModels+pymc3,这一套基本涵盖了数据分析数据挖掘所需要用到的所有工具.好处是可以处理单机性能下的所有数据分析和数据挖掘任务.坏处就是这一串的学习成本不低,因此人力成本也就不低,因此还是那句话,如果没有必要那就不要引入,具体还是要视业务需求来定

冷数据就已经可以推荐使用nas了.

> 开发数据

本地已经有nas的情况下,如果我们有代码开发和维护的需要,我们可以额外配一个代码托管机用于将github上的开发数据迁移到本地,并在本地架设openvpn,gitlab,jenkins.而其他数据则可以从u盘移动硬盘中迁移到nas里做统一管理.

由于开发数据全部放到了本地,那么我们就会需要有在外网环境下访问本地的需求,因此我们就会需要openvpn+ddns,外网环境下我们可以通过vpn的方式访问本地环境,这也为后续的一些计算密集型的离线任务放在本地工作站进行提供了条件.

#### 数据ETL方案

既然有了数据分析的需求,自然的就会有从原始数据到分析结果全程的数整备需求以及定时执行任务的需求,这个时候就会需要使用数据ETL工具.ETL工具通常是定时执行的批处理任务,可以理解为以时间截断数据分批处理,最终获得到需要的结果.

相对比较常用的是[airflow](http://airflow.apache.org/docs/stable/),这个工具现在在阿帕奇基金会下,完全开源,功能全面,后续的工具介绍部分会详细介绍.这个工具优点是可以和其他技术栈比较完美的结合

1. 可扩展性极佳.它可以单机部署,在业务需求量不大的情况下足以应付,在下一阶段可以切换为基于dask的集群部署,老的单机实例也不需要舍弃,作为开发测试实例可以继续发挥余热.
2. 使用python语言编写,也使用完整的python生态,对使用第二种数据分析方案的来说没有额外的心智负担.
3. 可以编写计算图,每步的结果可以带入下一步作为参数
4. 有监控ui,可以直观的管理执行流程.

#### 事件驱动方案

另一方面一些对实时性有要求的任务需要事件驱动,这就得借助消息队列了,这个阶段依然是两个选择:

+ 使用pg作为消息中间件,具体就是使用pg自带`notify/listen`命令做发布订阅.这个方案相对是学习成本最低的,,可以用作发布订阅模式,在不做分布式/多实例部署的情况下完全可以满足需求.

+ 使用redis作为这个消息中间件,这个方案相对更具可扩展性.

    1. 性能够强,可以满足实时性要求,而且有集群模式,在后续阶段可以使用集群提高可用性.
    2. 数据结构多样,可以满足各种需求:
        + Redis 5.0新增加了流数据结构,支持`Consumer Group`并且可以做消费确认,
        + pub/sub模式可以直接作为广播器使用,一些不需要消费确认的任务完全可以使用它
        + list数据结构,一些不需要消费确认的任务可以用作传统的生产消费模式.

    3. 可以在其他地方做贡献
        + 作为缓存将最热的数据放入其中降低数据库压力
        + 作为布隆过滤器使用
        + 用于去重
        + 用于在线用户计数等

#### 流处理方案

除了ETL批处理外,另一种数据处理方式叫流处理.数据中有用的信息实际上是有限的,流处理可以大致理解为缓存+筛选+统计函数好处是不依赖ETL,高效可持续

这个阶段可以使用的流处理方式比较推荐的有:

+ 使用pg的`pipelinedb`插件做流处理,好处是学习成本低,依然是postgresql,sql语句就可以完成所有任务,并且可以复用pg的其他技术,也方便管理.坏处也在pg上,pg的集群化不好用,`pipelinedb`不利于扩展,要扩展只能为不同业务各自起一个`pipelinedb`实例,但pg本身又略重.

+ 使用python包`streamz`,这个方案好处在于
    1. 它是python模块,对于使用python技术的来说没有额外的心智负担,
    2. 灵活可扩展,因为是python模块所以可以复用上面的python数据科学技术栈,同时支持与dask集群结合
    当然了坏处也有,就是python本身性能低下.


#### 数据服务方案

一些数据处理完后是要让业务端使用的,一些算法也是在数据这边训练好后要让业务端调用的,这种时候就需要数据提供对应的服务.可以看出数据侧提供的服务都是无状态的,以算法服务为主,因此没有必要使用RESTful接口,一般我们会使用rpc技术,比较通用的就是grpc了.这个技术我们后面也会讲到.gprc有官方的python实现,性能应付这个阶段足够了,如果单一服务不能满足也可以使用负载均衡方案起多实例.

#### 本地服务

在本地内网我们需要nas,如果需要限制员工的外网访问情况,也会需要软路由,如果需要有代码开发,那么gitlab和jenkins也需要,这些由于都不是那种重负载的需求,所以并不需要很贵的硬件,比如之前的星际蜗牛这些就是很好的服务宿主机,主要的机器成本在硬盘上,通常这个阶段4个4t的硬盘组raid6就已经很可以了,除开硬盘外的成本一台机器不会超过500元,通常最多两台就足够了.

#### 总结

这个阶段业务数据使用`postgresql`,业务数据服务使用`grpc`,分析数据使用`postgresql`保存,分析使用`sql+excel`或者`sql+pandas`,事件驱动使用`Redis`,流处理使用`pipelinedb`或者`streamz`,ETL使用`airflow`

可以看出初期阶段我们会大量使用`postgresql`和其扩展,因此sql是必备技能.而上一个阶段的`excel`依然是一种过度和补充.同时`python`也是这个阶段的主要可用工具之一,`airflow,streamz,pandas等`都是python的工具,

### 扩张阶段

这个阶段企业会寻求快速扩张,往往会大量招聘,大量引入新技术.这个阶段的技术选型主要是解决数据规模扩大的问题.在要处理的具体问题上其实没有任何变化.这个阶段主要需要引入的技术就是所谓的大数据技术,同时需要开始对数据的生命周期要做好控制,对服务质量提出要求.

+ 使用hdfs/hive/对象存储保存温数据
+ 使用spark/dask做大规模数据的分布式计算
+ 使用k8s/docker swarm 部署分布式服务应付高并发
+ 使用kafka提高流数据的吞吐量

#### 大数据技术选型

大数据技术几乎没有什么选择的余地,但在怎么用上可以给出一些建议

+ spark更加适合作为hive的sql引擎使用而非分布式计算工具,因为它是java体系下的产物,天生对python支持不好,并不适合以python作为基本工具的数据人员,也无法利用python自己的数据科学生态.也就是说spark/hive应该被看做是一个专用于大规模温数据的分布式数据库.

+ spark/hive体系适合做离线计算,流处理的选型可以考虑spark-streaming或者直接监听流用golang/python进行处理,

+ 使用dask做为大数据计算工具构建算法提供服务,如果有条件可以结合k8s做好动态资源调配,这样可以节省资源.

+ 除非不需要毫秒级延迟的实时性并且特别需要持久化流中的数据,否则不建议使用kafka替代redis的streams,在实时性要求高的场景中redis依然效果拔群.kafka只是用于需要高吞吐量的场景.

+ Elasticsearch+Kibana+logstack及其变种是收集服务日志的经典工具.扩张阶段服务日志同样是非常重要的分析数据.

#### 数据中台

这应该是2019年新炒热的一个名词,来自阿里,核心思想是数据共享,其诞生是为了应对像双十一这样的业务高峰,应对大规模数据的线性可扩展问题,应对复杂业务系统的解耦问题.而在技术/组织架构等方面采取了一些变革,但其本质上还是一个平台,阿里称之为"共享服务平台(Shared Platform as Service/SPAS)".SPAS采用的是基于面向服务的架构SOA理念的"去中心化"的服务架构,所有的服务都是以"点对点"的方式进行交互.数据中台是指通过数据技术,对海量数据进行采集,计算,存储,加工,同时统一标准和口径.可以理解为是本文所讲内容的一个统一管理平台.更多的是统一不同业务间的数据接口,做到数据,算法可以轻易共享.在这个概念之前出现过的概念有:

+ 数据仓库--提供统一的数据存储,查询平台
+ 数据中心--提供大数据的计算能力

实际上所谓数据中台也是在这俩个概念上发展而来,做的事情其实就是

1. 业务数据统一收集,存储,清洗,计算,抽取并最终构成数据资产(就是特定领域数据资源)以服务的形式提供统一接口供业务调用
2. 由数据训练得到的算法同样作为资源以服务的形式提供统一的接口给业务层调用.

因此其概念核心是数据共享,背后依然还是平台化,服务化的思路.

在前面的阶段我们就已经介绍了可以使用grpc来作为服务化的主要工具,前面请求量不大的时候使用python的grpc实现完全可以满足要求,但这个阶段恐怕就不行了,在综合学习成本,开发效率和执行效率的情况下推荐使用golang实现.

#### nas的升级

这个阶段往往不光是业务扩展,成员,工作地点也会扩展,这个时候我们的nas又会多一个需求--开发数据的多地同步.

#### 总结

扩张阶段就是优化业务扩张业务,在业务端主要的矛盾是高并发高吞吐量,在数据分析端主要的矛盾是单机无法完成分析任务.这个阶段可能需要引入`kafka`,`hive`和`spark`,好在这两个服务依然可以使用python,同时主要还是跑的sql,而`dask`依然是python的工具.在服务化方面推荐使用golang替代python.

到这个阶段为止,我们的多数业务数据还是在线上的,在线下我们只是需要每个办公地点有如下服务:nas,openvpn服务,gitlab服务,jenkins服务,软路由,这些可以分在不同机器上也可以nas一台机器其他一台机器.
机器算上硬盘的成本不需要超过10000.

### 稳定阶段

这个阶段基本上只是在前面的基础上做加法而已.本身结构已经不再需要变动了.这个时候做的更多的是

1. 提高数据安全性

2. 提高算法质量

3. 提高执行效率

如果有想法从云上下来自己建机房,这个时候需要做数据迁移,数据迁移一定要谨慎.

### 淘汰阶段

任何事物都有生命周期,江山代有才人出,各领风骚数百年.这个阶段并非不再盈利,而是往往业务被其他东西替代,比如胶卷照相机基本上已经退出了历史舞台,但柯达的胶卷依然在小众市场活得好好的,这个阶段更多的是找出路--缩减规模并找到合适的小众市场活下去.因此这个阶段主要要做的是逐步的从复杂庞大的数据系统中整理出核心业务,化繁为简节省资源.这个过程思路基本是上面的过程反过程,使用的技术栈视需求和数据规模而定,最终可以退回到使用execl做最简单数据收集分析的阶段.
