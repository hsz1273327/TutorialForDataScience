# 数据规模和数据管理

随着数据规模的增加,数据管理手段和工具都需要做出响应变化,之所以不同规模的数据要用不通的技术手段,根本上来说是机器的资源无法满足大规模存储/计算的需求.再往深了说是高资源配置的机器太贵了.因此可以看到几乎所有的大数据解决方案都是集群化方案--利用大量便宜的低配置机器组成集群,通过调度管理程序统一调配资源:

1. 将任务拆分重构为子任务构成的任务图放入调度器
2. 借助队列将任务分发到多台机器处理然后再聚合


数据管理当然也需要根据不同的数据规模来调整数据管理方式和使用的工具.



## 不同规模下的技术选型

基本上技术选型需要考虑的是资源成本和预期收益,说到底数据是为盈利服务的.

比如一个赔钱的业务,那它就没有必要做什么数据管理,因为投的多赔的多;
如果是小本经营比如小区里开个小面包店,那它就比较适合将业务和数据结合管理,买台2000块的电脑,装个office,每天一张excel表就足以解决问题;
如果面包店开大了,连锁了有了两家分店,那不同分店间的数据对账就成了问题,这时候就需要一个所谓的数据中心(总店里电脑升级下配置,加块ssd,和运营商开下对外端口)来维护每个店的资源和资金;
面包店希望做到更好的提高回头客的比例,希望通过会员制等措施知道客户希望买到什么样的面包,这个时候就需要有算法,有分析的进入,就会有推荐,用户调研,决策支持等需求,这个时候就需要再升级数据中心的配置,更大的内存更多强的cpu,甚至多机组成集群,需要有定时任务分析每天的交易情况;
随着面包店的扩大数据越来越多,数据存在哪里成了问题,一来全存存不下,要想存下需要花很多钱买硬盘,二来数据多了搜索,调用性能堪忧,这时候数据就需要按热度分出生命周期,处在生命周期不同阶段的数据放在不同的工具中,用的多的数据放在高性能高价的存储介质中,用的少的只是留档就放在最便宜的设备中.数据的分析也分析不过来--用于分析的数据规模大于单机的内存,这个时候就要借助分布式计算框架,比如spark,比如dask.
再进一步的面包店希望数据的分析结果可以实时的反馈给门店,快速响应跟上市场的变化,这个时候就需要引入流的概念,使用流处理工具.

上面的例子可以看出技术只是手段,是为了解决问题才发展出来的,因此什么阶段使用什么样的技术,不同阶段间技术如何过度就成了技术选型需要考虑的问题.

本文给出的技术选型方案是渐进式的,没有替换只有增加和撤销,这点需要注意,另外在可以满足需求的情况下不要没事尝试新的技术或者使用下一阶段的技术,尝试新技术是个试错的过程,必然会有大量失败浪费大量人力物力,尤其是在公司还规模小的时候.不少公司是折腾死的.

另外一个需要注意的是关于部署的问题,原则上我个人不支持直接部署,更加支持使用docker部署一切需要部署的业务程序.利用容器配合k8s或者swarm技术可以大大降低运维成本.而一些基础组件比如数据库,缓存,消息中间件等为了更加可靠更加建议如果不是自建机房就购买运营商的专业服务,这样可以省很多运维成本.如果是自建机房则建议单独购买机器专门配置运维.



### 起步阶段

在业务初期,盲目的追求新技术往往得不偿失,业务初期的首要目标永远是赚钱,先能活下去再考虑如何提高效率.如果提高了效率也不能赚钱那就更加得不偿失了,因为业务小,所以数据量也小,一天的数据量可能也就一个100M以下的excel文件就可以保存.因此快速试错快速失败才是业务初期对数据的最大需求.正如上面的例子所说,excel(office,wps)就是初期最好的工具:

1. 廉价
    本身几乎免费,人力方面--几乎人人都会用excel而且学习成本极低.这项技能甚至都不用写到招聘需求里
    
2. 功能够用
    即便不会vb编程,不会写宏,excel也已经可以用作记录,筛选,查找,分类,可视化的功能,足以满足绝大多数数据方面的需求.
    
3. 存储灵活
    excel说白了是文件存储,这就意味着可以很灵活的存储,可以放硬盘,移动硬盘,u盘都行
  
4. 足以应付简单分析需要


### 初期阶段

此处业务初期指业务已经找到了盈利模式,可以稳定增长,可以养得起技术团队并且有继续做大想法的阶段.这个阶段的特点是业务已经成型,但规模没有上去.这个阶段的主要任务就是修好内功打好地基,为后续扩大规模抢占市场提供支持.

这个阶段往往是企业成败的关键,往往一个企业的骨架就是在这个时候定型的,通常这个阶段只会存在最长1年时间,但这一年之后的所有行为可能都是这一年中决定的延续.

这个阶段企业要定好利益分配框架,权力分配架构,技术架构,当然了企业本身架构不是本文的讨论范围,而且远比技术架构的成型原因复杂的多.一个足够优秀技术架构可以让企业在快速扩张时在技术方面降低内耗,专心于业务.但技术架构往往也是由利益分配框架和权力分配架构影响形成的,比如创始人中有精通java的并且权力很大,那很容易就影响到技术栈会用全套java.没有人懂技术,那很可能就是谁出钱多就听谁瞎指挥.因此比较建议任何初创团队都应该有一个懂数据的创始人.

当然了能安然度过这个阶段其实已经是胜利了,毕竟很多企业活不过两年.

这个阶段的数据量会上来,一天的数据量可能可以上G,但基本不会超过100G,基本还是在单机可以处理的程度.但基本的数据相关架构就已经可以根据需求完善起来了.

这个阶段建议不要自建机房,而是使用阿里云腾讯云aws这样的服务商提供的虚拟主机和运维服务.自建机房不光是费钱的问题,更多的是需要耗费人力,运维工作非常专业化,专业人员贵,非专业人员又难以解决问题.救我了解有不少公司原本有自建机房的也都纷纷上了云.这个阶段并不适合自建机房.如果有自建机房的需求建议在稳定阶段逐步迁移.

#### 存储方案

初期存储方案一般是使用数据库.需要用到数据库时比较建议直接使用postgresql,而不是跟风用什么mysql或者其他nosql数据库.

1. 廉价
    postgresql本身开源,任何人都可以安装使用,pg使用sql语句作为通用的交互接口,任何学过数据库的人一定都会使用sql,因此人力成本上相对也不高.pg的运维成本也不高,只是国内用的人少会让人觉得难,实际上它的文档相当齐全,本身设计优秀几乎不需要额外的运维.至于学习成本其实更低了,官方文档有高质量的中文翻译,大多数问题都可以看它解决.
    
2. 功能全

    postgresql几乎是最全能的数据库.丰富的扩展让它可以满足几乎所有需求.
    
3. 使用的生命周期长

    postgresql可以在进入整个业务技术栈后就一直有一席之地.开始可以全部使用它来存储数据,甚至可以做广播器.慢慢的业务扩大了可以分表,可以将一些特殊数据存入其扩展,比如时序数据库timescale,再然后可以作为热数据的存储工具.
    
当然这个阶段就需要有相关的技术人员参与了,建议招聘有编程能力的专业技术人员或者自己学习运维,而不是只会改配置的所谓运维.一个这样的人可以管整个数据层,在下一个阶段之前都可以不需要额外的人手,后续只是给他找帮手而已.


#### 数据分析方案

当不再满足于存储和简单查询这样的方式来利用数据时,比如要分析用户时,就需要专业的数据分析人员了.这个阶段初期一样需要的技术还是postgresql和excel.但成本是在人力上,数据分析数据挖掘是技术活,并不是人人可以做,这个阶段一般技术栈有两种

1. sql进阶+excel进阶,sql语句本身图灵完备,pg完全支持复杂的sql查询语句,那问题就在人会不会写复杂的查询语句了.查出需要的数据后可以导入excel借助插件做方差分析等数据分析工作,并且可以使用excel自带的工具做数据可视化.这个技术栈好处是没有引入任何新的技术,只是在老技术上做深化.事实上很多传统行业都是这么做的.但瓶颈实际上在excel上,excel可以处理的数据量有限,文件一旦过大无论打开还是计算都会很低效;同时支持的算法少,自己写算法也麻烦.当然如果这个方案足够使用那就没必要引入新的技术栈了.

2. sql进阶+python数据科学工具组,所谓的python数据科学工具组大致就是numpy+scipy+pandas+sklearn+StatsModels+pymc3,这一套基本涵盖了数据分析数据挖掘所需要用到的所有工具.好处是可以处理单机性能下的所有数据分析和数据挖掘任务.坏处就是这一串的学习成本不低,因此人力成本也就不低,因此还是那句话,如果没有必要那就不要引入,具体还是要视业务需求来定

#### 数据ETL方案

既然有了数据分析的需求,自然的就会有从原始数据到分析结果全程的数整备需求以及定时执行任务的需求,这个时候就会需要使用数据ETL工具.ETL工具通常是定时执行的批处理任务,可以理解为以时间截断数据分批处理,最终获得到需要的结果.

相对比较常用的是[airflow](http://airflow.apache.org/docs/stable/),这个工具现在在阿帕奇基金会下,完全开源,功能全面,后续的工具介绍部分会详细介绍.这个工具优点是可以和其他技术栈比较完美的结合

1. 可扩展性极佳.它可以单机部署,在业务需求量不大的情况下足以应付,在下一阶段可以切换为基于dask的集群部署,老的单机实例也不需要舍弃,作为开发测试实例可以继续发挥余热.
2. 使用python语言编写,也使用完整的python生态,对使用第二种数据分析方案的来说没有额外的心智负担.
3. 可以编写计算图,每步的结果可以带入下一步作为参数
4. 有监控ui,可以直观的管理执行流程.



#### 事件驱动方案

另一方面一些对实时性有要求的任务需要事件驱动,这就得借助消息队列了,这个阶段依然是两个选择:


+ 使用pg作为消息中间件,具体就是使用pg自带`notify/listen`命令做发布订阅.这个方案相对是学习成本最低的,,可以用作发布订阅模式,在不做分布式/多实例部署的情况下完全可以满足需求.

+ 使用redis作为这个消息中间件,这个方案相对更具可扩展性.

    1. 性能够强,可以满足实时性要求,而且有集群模式,在后续阶段可以使用集群提高可用性.
    2. 数据结构多样,可以满足各种需求:
        + Redis 5.0新增加了流数据结构,支持`Consumer Group`并且可以做消费确认,
        + pub/sub模式可以直接作为广播器使用,一些不需要消费确认的任务完全可以使用它
        + list数据结构,一些不需要消费确认的任务可以用作传统的生产消费模式.

    3. 可以在其他地方做贡献
        + 作为缓存将最热的数据放入其中降低数据库压力
        + 作为布隆过滤器使用
        + 用于去重
        + 用于在线用户计数等
        
#### 流处理方案

除了ETL批处理外,另一种数据处理方式叫流处理.数据中有用的信息实际上是有限的,流处理可以大致理解为缓存+筛选+统计函数好处是不依赖ETL,高效可持续

这个阶段可以使用的流处理方式比较推荐的有:

+ 使用pg的`pipelinedb`插件做流处理,好处是学习成本低,依然是postgresql,sql语句就可以完成所有任务,并且可以复用pg的其他技术,也方便管理.坏处也在pg上,pg的集群化不好用,`pipelinedb`不利于扩展,要扩展只能为不同业务各自起一个`pipelinedb`实例,但pg本身又略重.

+ 使用python包`streamz`,这个方案好处在于
    1. 它是python模块,对于使用python技术的来说没有额外的心智负担,
    2. 灵活可扩展,因为是python模块所以可以复用上面的python数据科学技术栈,同时支持与dask集群结合
    当然了坏处也有,就是python本身性能低下.

#### 数据服务方案

一些数据处理完后是要让业务端使用的,一些算法也是在数据这边训练好后要让业务端调用的,这种时候就需要数据提供对应的服务.可以看出数据侧提供的服务都是无状态的,以算法服务为主,因此没有必要使用RESTful接口,一般我们会使用rpc技术,比较通用的就是grpc了.这个技术我们后面也会讲到.



### 扩张阶段

这个阶段企业会寻求快速扩张,往往会大量招聘,大量引入新技术.这个阶段的技术选型主要是解决数据规模扩大的问题.在要处理的具体问题上其实没有任何变化.这个阶段主要需要引入的技术就是所谓的大数据技术,同时需要开始对数据的生命周期要做好控制.

+ 使用hdfs/hive/对象存储保存冷数据
+ 使用spark/dask做大规模数据的分布式计算

#### 大数据技术选型

大数据技术几乎没有什么选择的余地,但在怎么用上可以给出一些建议

+ spark更加适合作为hive的sql引擎使用而非分布式计算工具,因为它是java体系下的产物,天生对python支持不好,并不适合以python作为基本工具的数据人员,也无法利用python自己的数据科学生态.也就是说spark/hive应该被看做是一个专用于大规模冷数据的分布式数据库.

+ spark/hive体系适合做离线计算,

+ pg依然可以在大数据环境下发挥作用`Greenplum`在pb以下优于hive/spark,适合作业务分析,同时,离线计算后的结果很适合放到`Greenplum`用于查询.

+ 使用dask做为大数据计算工具构建算法提供服务,并结合k8s做好动态资源调配,这样可以节省资源.

+ 除非不需要毫秒级延迟的实时性并且特别需要持久化流中的数据,否则不建议使用kafka替代redis的streams

#### 数据中台

这应该是2019年新炒热的一个名词,来自阿里,核心思想是数据共享,其诞生是为了应对像双十一这样的业务高峰,应对大规模数据的线性可扩展问题,应对复杂业务系统的解耦问题.而在技术/组织架构等方面采取了一些变革,但其本质上还是一个平台,阿里称之为"共享服务平台(Shared Platform as Service/SPAS)".SPAS采用的是基于面向服务的架构SOA理念的"去中心化"的服务架构,所有的服务都是以"点对点"的方式进行交互.数据中台是指通过数据技术,对海量数据进行采集,计算,存储,加工,同时统一标准和口径.可以理解为是本文所讲内容的一个统一管理平台.更多的是统一不同业务间的数据接口,做到数据,算法可以轻易共享.在这个概念之前出现过的概念有:

+ 数据仓库--提供统一的数据存储,查询平台
+ 数据中心--提供大数据的计算能力

实际上所谓数据中台也是在这俩个概念上发展而来,做的事情其实就是

1. 业务数据统一收集,存储,清洗,计算,抽取并最终构成数据资产(就是特定领域数据资源)以服务的形式提供统一接口供业务调用
2. 由数据训练得到的算法同样作为资源以服务的形式提供统一的接口给业务层调用.

因此其概念核心是数据共享,背后依然还是平台化,服务化的思路.


### 稳定阶段

这个阶段基本上只是在前面的基础上做加法而已.本身结构已经不再需要变动了.这个时候做的更多的是

1. 提高数据安全性

2. 提高算法质量

3. 提高执行效率

如果有想法从云上下来自己建机房,这个时候需要做数据迁移,数据迁移一定要谨慎.


### 淘汰阶段

任何事物都有生命周期,江山代有才人出,各领风骚数百年.这个阶段并非不再盈利,而是往往业务被其他东西替代,比如胶卷照相机基本上已经退出了历史舞台,但柯达的胶卷依然在小众市场活得好好的,这个阶段更多的是找出路--缩减规模并找到合适的小众市场活下去.因此这个阶段主要要做的是逐步的从复杂庞大的数据系统中整理出核心业务,化繁为简节省资源.这个过程思路基本是上面的过程反过程,使用的技术栈视需求和数据规模而定,最终可以退回到使用execl做最简单数据收集分析的阶段.
