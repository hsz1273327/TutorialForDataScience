# 数据的生命周期

和其他任何东西一样,数据也有生命周期,数据生命周期管理(data life cycle management,DLM)则是一种基于策略的方法,用于管理信息系统的数据在整个生命周期内的流动--从创建和初始存储到它过时被删除整个过程.大致可以分为如下几个大块

1. 创建阶段,从业务信息中提取有价值的部分构造成数据并放入整个数系统中进行流转

2. 热数据阶段,一般数据在越新的时候越有价值,刚进入系统的数据往往可以作为消息使用(流处理),稍微过时一点的数据也会被查询使用.再过期一些,使用近期数据的一些统计量往往可以比较客观的反映当前的业务状况.

3. 冷数据阶段,当数据失去了时效性,往往我们不会再直接使用它,而是将它作为一些离线统计任务或者预测模型的训练样本使用.

4. 删除阶段,当数据已经几乎不再被任何地方用到了,那从成本考虑我们往往会将其从这个数据系统中删除.

## 不同生命周期时数据的载体

由于机器成本和数据的价值的不同,我们通常会按上面的顺序选择从贵到便宜,从高性能到低性能的工具作为载体.

### 创建阶段

创建阶段时,我们应该视业务场景来选择使用的工具

+ 如果我们希望数据尽量有时效性那我们因该将其作为事件来创建,因此主要的载体是消息队列或者广播器,如果对实时性要求很高,但可以接受消息丢失,那么我们可以选择redis的PUB/SUB模式;如果要保证消息的完整性和顺序性,则可以使用kafka或者redis的stream模式来做.当然我们也可以将其组合使用.

+ 如果我们的数据只需要可以被查找到用于离线的静态分析,那么我们应该将其写入hive或者postgresql这样的数据库系统.使用那种数据库系统需要根据数据的使用频率,数据规模进行评估.

+ 如果我们的数据需要结合业务大量被访问,那我们应该将其写入redis这样的缓存工具中

### 热数据阶段

热数据阶段通常由3种载体

1. 流处理数据中间件,比如pg的插件piplinedb,kafka/redis+spark-streaming/dask+streamz,这些方案并没有太大区别,只是做好消费端的并行化处理防止消息不能及时处理完阻塞就好,流数基本不会直接落地到数据库,而是被处理成需要的聚合量后再存入指定位置(业务数据库,特征库,模型库甚至直接推送给客户等).

2. 时间序列数据库,与时间密切相关的热数据都可以使用时间序列数据库.这里就需要做出选择了,influxdb开源版本只有单机,配套工具并不多,而且查询不是完整的sql语言,表现力不足,限制也多,更关键的是数据量一大,写入一多就极易oom,因此不建议使用,更加推荐的是postgresql的插件timescaledb.它的内存使用率增长相对平缓,而且支持完整sql,虽然在吞吐量,数据压缩性能上比不上influxdb但应付热数据阶段的需求就足够了.

3. 缓存数据库通常视redis,这种一般是存放数据缓存的,一般也会设置过期保证数据是热数据.

### 冷数据阶段

数据在什么时候由热数据变成冷数据这个要看业务需求,但基本可以这样判定:

1. 数据不会再被单独取出来使用

2. 数据不会再被频繁的取出来使用,使用间隔以天计数.

有以上特征的数据基本就可以作为冷数据处理了.通常我们会使用ETL工具定期的将数据从缓存库转移到存放冷数据的媒介,比较推荐的ETL工具有airflow和[easy scheduler](https://github.com/apache/incubator-dolphinscheduler)尤其是后者,虽然年轻,但确实方便管理,目前的版本还有些小bug但已经足够支持业务使用了.
而冷数据通常比较大,其存放一般也是使用的相对廉价的介质,比如aws上的s3对象存储,或者是hdfs集群.其存储形式一般也以文件为主,通常为了压缩率和查询效率会使用列存储格式,比如`Parquet`,每次存储一般都是以时间段为划分,比如按小时,按天来划分文件,具体如何划分需要考虑业务和单文件的容量

### 删除阶段

删除阶段通常是为了用更加低廉的方式保存过期数据.比如我们保留1年的数据作为冷数据那比较可能的操作是--在每年的1月一日将去年一整年的数据压缩打包后下载到本地的廉价大容量硬盘或者磁带同时每个月初固定删除上一年上个月的数据.

通常存储的数据格式和冷数据阶段一样,但其中数据的间隔时间更长,比如是按月记录,然后再进行压缩.

## 不同数据的生命周期

数据和数据当然是不一样的.我们大致上可以分为如下几种:

1. 静态数据

    这种数据往往是业务的起点,比如音乐软件库中的音乐就是静态数据.这种数据的特点是更新不频繁,一直需要保持可访问状态,同时一有上架下架消息就会影响到许多的业务,因此比较合适的处理方法是在创建阶段创建的是上架/下架/修改的事件数据,通过在中间件中广播上架下架修改事件让依赖对应数据的业务进行处理.

    这种数据最好更多的关注其并发性能,因为他们往往在业务上需要被频繁访问术语OLTP业务,这种比较好的方式有两个:
    1. 数据库读写分离,一写多读,分摊查询压力
    2. 使用redis缓存,查询访问全部走redis缓存

    如果要针对静态数据做OLAP业务,那么比较好的方法是将对应表同步复制到OLAP工具,比如hive,ElasticSearch这些.这种数据一般也不用区分冷热,也都不会删除,删了基本算事故.

2. 事件数据

    这种数据就是比较典型的了,它一般会走完从创建到删除的整个流程.通常它们不会被直接取出来用,而是分批的做统计数据.它反应的是业务中的事件,是被动接收到的或者被动收到后基于规则创建的,比如用户点击了某个按钮听了首什么歌,用户对某个视频取消了收藏,5分钟内一个用户请求都没有,连续1小时机器负载超过90%这些.这种数据往往是数据管理的关键,它可以反应业务的状态.

3. 基于事件流的统计数据

    这种数据这种数据往往用于作为近实时特征参与数据建模,比如由用户收听结束事件获取到的歌曲收听进度情况计算某个歌曲的热度,某个用户对它或者它所在类别,歌手的喜爱程度.右或者是短时间内定时任务计算流的缓存获取并发布的数据,比如某个商品每5分钟发布一次它在近1小时窗口期内被曝光的次数和点击的次数,这种数据是事件数据的延伸,同样应该走完从创建到删除的整个流程.

4. 定时静态分析得到的统计数据

    比如每天凌晨3点定时计算每个用户的留存情况,付费情况这种,这种数据往往对产品设计很有帮助,但并不适合作为事件发布,因此这种数据应该直接存OLAP工具中.

5. 由事件数据,基于事件流的统计数据,定时静态分析得到的统计数据中得到的最近[截面数据](https://baike.baidu.com/item/%E6%88%AA%E9%9D%A2%E6%95%B0%E6%8D%AE/3906731?fr=aladdin),

    这种数据往往也会对业务有一定的作用,比如前一天得到的某个用户当天看的视频类型分布完全可以作为预测这个用户今天会看什么视频的依据.最近5分钟内最热的视频也完全可以作为对无行为用户的推荐召回的一部分.昨天借贷用户的质量也可以作为是收紧还是放松今天借贷用户门槛的一个参数.因此这部分应该和静态数一样处理,只是需要注意这种数据需要整体先删除再写入以保证其时效性.

