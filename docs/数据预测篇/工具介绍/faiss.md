# faiss

faiss是facebook开源的用于快速计算解决大规模向量的最近邻问题的工具.它的使用有如下限制:

1. 向量和矩阵需要相同维度
2. 一些索引需要通过训练来构建

faiss本质上就干两件事

1. 通过矩阵构建索引

    ```python
    quantizer = faiss.IndexFlatL2(d) #倒排需要用一个粗粒度索引作为参数
    index = faiss.IndexIVFPQ(quantizer, d, nlist, M, nbits)
    index.train(data)# 有的要训练
    index.add(data)
    ```

2. 向量在构建的索引中查找相似

    ```python
    dis, ind = index.search(query, 10)
    ```

因此faiss就是围绕索引展开的.

索引的指标可以看作如下三个维度

1. 精度,是否可以精确找到
2. 查询性能,查询操作要花多少时间
3. 存储性能,建立索引需要多少存储空间

因此索引也可以看作由如下部分组成:

1. 索引类型(构建和查找算法)
2. 索引编码方式

一般来说索引类型确定了那么其基本性质也就确定了,使用不同的编码方式就是在精度,查询性能,存储性能间进行微调而已.编码越复杂一般查询性能越差精度越差但存储性能越好.

下面是支持的索引类型列表

## `Flat`索引

Flat索引只是将向量编码为固定大小的codes,并将它们存储在`ntotal * code_size`字节数组中.

在搜索时所有向量都被顺序解码并与查询向量进行比较,不过IndexPQ是在压缩域进行比较,这会比较快.

`Flat`索引中有唯二的两种精确索引,因此如果对精度有要求就只能使用这两种之一.

### 支持的操作

Flat索引类似于 C++ 向量,它们不存储矢量的ID,因为在许多情况下顺序编号就足够了.因此:

+ 不支持`add_with_id`(但是可以将它们内嵌于IndexIDMap以使用该功能)
+ 支持高效的直接矢量访问(使用reconstruct和reconstruct_n)
+ 支持使用删除remove.这会缩小索引并更改编号.


| 索引类型               | 索引精度 | 使用前提       | 搜索方式     | 向量编码                                          | 是否需要训练 |
| ---------------------- | -------- | -------------- | ------------ | ------------------------------------------------- | ------------ |
| `IndexFlatL2`          | 精确索引 | ---            | `l2`欧氏距离 | ---                                               | 否           |
| `IndexFlatIP`          | 精确索引 | 向量是标准化的 | `cos`        | ---                                               | 否           |
| `IndexScalarQuantizer` | 近似索引 | ---            | `l2`欧氏距离 | `QT_fp16`/`QT_8bit`/`QT_6bit`/`QT_4bit`(标量量化) | 是           |
| `IndexPQ`              | 近似索引 | ---            | `l2`欧氏距离 | `PQ`(乘积量化)                                    | 是           |

## `IVF`索引

倒排索引.以损失找到最近邻的精度为代价来加快处理速度的典型方法是采用诸如`k-means`之类的分区技术.相应的算法有时被称为`Cell-probe`方法.

这种算法的核心思想是在构造索引时先为每个索引分好区,查找时则根据分区查找.

倒排索引说白了就是拿空间和精度换时间,在不太在意内存占用的情况下倒排索引表现良好,同时它支持gpu,因此是综合性能最好的选择

### 支持的操作

1. 需要使用flat索引作为粗粒度量化器.即先构造一个flat索引,再将其作为参数传给倒排索引.
2. 需要设置一个k值,这个k值就是分区数,k的取值需要调优

| 索引类型                  | 索引精度 | 向量编码                                          | 是否需要训练 |
| ------------------------- | -------- | ------------------------------------------------- | ------------ |
| `IndexIVFFlat`            | 近似索引 | ---                                               | 是           |
| `IndexIVFScalarQuantizer` | 近似索引 | `QT_fp16`/`QT_8bit`/`QT_6bit`/`QT_4bit`(标量量化) | 是           |
| `IndexIVFPQ`              | 近似索引 | `PQ`(乘积量化)                                    | 是           |
| `IndexIVFPQR`             | 近似索引 | `PQ`(乘积量化)                                    | 是           |

`IndexIVFPQR`即 `IndexIVFPQ`+rerank

## `Hierarchical Navigable Small World`索引

`Hierarchical Navigable Small World`(级联式图搜索)是一种基于向量图的索引方式.
在搜索时,将以尽快收敛到最近邻的方式搜索图.

HNSW取决于一些重要参数:

+ `M`是图中使用的近邻数,较大的M更准确但会占用更多内存
+ `efConstruction` 是add时的探索深度
+ `efSearch` 是search时探索深度

图索引适合在完全不在意内存占用的情况下使用,内存放开用的情况下它可以有最好的性能,同时还不需要训练.

### 支持的操作

1. 不支持`add_with_id`(但是可以将它们内嵌于IndexIDMap以使用该功能)
2. HNSW不支持从索引中删除向量,这将破坏图结构
3. 不需要训练，不支持GPU

 不支持`add_with_id`(但是可以将它们内嵌于IndexIDMap以使用该功能)

| 索引类型          | 索引精度 | 向量编码                                          | 是否需要训练 |
| ----------------- | -------- | ------------------------------------------------- | ------------ |
| `IndexHNSWFlat`   | 近似索引 | ---                                               | 否           |
| `IndexHNSWSQ`     | 近似索引 | `QT_fp16`/`QT_8bit`/`QT_6bit`/`QT_4bit`(标量量化) | 否           |
| `IndexHNSWPQ`     | 近似索引 | `PQ`(乘积量化)                                    | 否           |
| `IndexHNSW2Level` | 近似索引 | `2Level`(两级编码)                                | 否           |
