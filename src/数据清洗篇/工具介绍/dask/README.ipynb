{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用dask做分布式计算\n",
    "\n",
    "dask是纯python的分布式科学计算框架,其旨在让熟悉python下数据科学工具的数据开发人员可以无痛的从单机版本的numpy,scipy,pandas,sklearn迁移到分布式计算,以适应大数据分析的需求,于此同时不失去python语言的灵活性.\n",
    "\n",
    "标准的dask集群部署方式(命令行方式)有大致3块结构:\n",
    "\n",
    "+ 分布式的数据结构接口用于构造计算图\n",
    "+ 调度器用于分发任务(启动命令`dask-scheduler`)\n",
    "+ worker运算节点(启动命令`dask-worker tcp://{host}:8786`)\n",
    "\n",
    "在此基础上还有几个借助已有分布式工具的部署方式:\n",
    "\n",
    "+ docker方式,其实就是命令行方式,只是借助docker集群提供算力,也是本文使用的方式\n",
    "\n",
    "+ Kubernetes方式,借助Kubernetes集群提供算力,它提供了docker方式不具备的动态调节资源的能力\n",
    "\n",
    "+ YARN/Hadoop方式,借助YARN/Hadoop集群提供算力,这种方式相当于把调度器和worker承包给了yarn\n",
    "\n",
    "+ 借助高性能计算框架作为调度器.这种一般公司没有."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## docker方式部署dask集群\n",
    "\n",
    "\n",
    "下面是一个简易的docker-compose文件\n",
    "\n",
    "```yml\n",
    "version: \"3.6\"\n",
    "\n",
    "services:\n",
    "  scheduler:\n",
    "    image: daskdev/dask\n",
    "    hostname: dask-scheduler\n",
    "    logging:\n",
    "      options:\n",
    "          max-size: \"10m\"\n",
    "          max-file: \"3\"\n",
    "    ports:\n",
    "      - \"8786:8786\"\n",
    "      - \"8787:8787\"\n",
    "    command: [\"dask-scheduler\"]\n",
    "  worker1:\n",
    "    image: daskdev/dask\n",
    "    hostname: dask-worker1\n",
    "    logging:\n",
    "      options:\n",
    "          max-size: \"10m\"\n",
    "          max-file: \"3\"\n",
    "    command: [\"dask-worker\", \"tcp://scheduler:8786\"]\n",
    "    \n",
    "  worker2:\n",
    "    image: daskdev/dask\n",
    "    hostname: dask-worker2\n",
    "    logging:\n",
    "      options:\n",
    "          max-size: \"10m\"\n",
    "          max-file: \"3\"\n",
    "    command: [\"dask-worker\", \"tcp://scheduler:8786\"]\n",
    "    \n",
    "  worker3:\n",
    "    image: daskdev/dask\n",
    "    hostname: dask-worker3\n",
    "    logging:\n",
    "      options:\n",
    "          max-size: \"10m\"\n",
    "          max-file: \"3\"\n",
    "    command: [\"dask-worker\", \"tcp://scheduler:8786\"]\n",
    "\n",
    "```\n",
    "\n",
    "这个配置方式用来测试绰绰有余,但并不适合生产环境使用,生产环境建议使用`Kubernetes`方式或者`YARN/Hadoop`方式.如果非要用docker方式,那也注意一定不要用warm自带的overlay网络,可以使用host方式pubish端口,所有的网络流量通过宿主机ip走内网流量.\n",
    "\n",
    "无论是swarm方式还是k8s方式部署dask集群,我们都需要用到dask的环境镜像[daskdev/dask](https://github.com/dask/dask-docker/tree/master/base).我们应该保持集群中每个节点使用的镜像一致,以防止不必要的麻烦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命令行方式的helloworld\n",
    "\n",
    "命令行方式的核心是启动调度器,调度器有一个默认的管理界面在`8787`端口.这个界面上我们可以看到连接着的集群的各个节点信息,以及任务节点的分布情况.\n",
    "\n",
    "\n",
    "\n",
    "而要使用集群计算我们需要连接到调度器的`8786`端口.这里我把远程机器上的调度器端口映射到了本地."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('localhost:8786') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333283335000\n"
     ]
    }
   ],
   "source": [
    "A = client.map(square, range(10000))\n",
    "total = client.submit(sum, A)\n",
    "print(total.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask集群任务的工作流基本都是一样:\n",
    "\n",
    "1. 连接集群,实例化一个客户端对象\n",
    "2. 利用封装好的分布式数据结构或者底层api构建计算图\n",
    "3. 提交任务,调度执行\n",
    "\n",
    "其他部署方式只是连接集群的方式不一样了而已\n",
    "\n",
    "\n",
    "![dask工作流](source/collections-schedulers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask的应用场景\n",
    "\n",
    "dask是为大数据设计的,因此如果数据规模小实际上并不适合使用它.如果你的数据无法放到单机内存中那就可以使用它,反之,好好使用numpy吧.\n",
    "\n",
    "dask不会让你的计算更快,它只是解决数据过大单机无法计算的问题,如果是为了让运算更快,建议使用numba或者cython加速,这个就是另一个话题了."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
